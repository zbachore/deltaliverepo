trigger:
- none

pool:
  vmImage: 'ubuntu-latest'

stages:
- stage: DeployToDev
  displayName: 'Deploy Notebooks to Dev'
  variables:
  - group: Databricks-Dev
  jobs:
  - job: DeployDev
    steps:
    - checkout: self

    - task: UsePythonVersion@0
      inputs:
        versionSpec: '3.x'

    - script: |
        curl -fsSL https://raw.githubusercontent.com/databricks/setup-cli/main/install.sh | bash
        databricks --version
      displayName: 'Install Databricks CLI v2'

    - script: |
        echo "Deploying notebooks to Dev..."
        databricks workspace import-dir dlt-config-demo /Shared/DLT/dlt-config-demo --overwrite
        databricks workspace import-dir dlt-scd-demo /Shared/DLT/dlt-scd-demo --overwrite
      displayName: 'Deploy Notebooks to Dev Workspace'
      env:
        DATABRICKS_HOST: $(DATABRICKS_HOST)
        DATABRICKS_TOKEN: $(DATABRICKS_TOKEN)

- stage: DeployToQA
  displayName: 'Deploy Notebooks to QA'
  dependsOn: DeployToDev
  variables:
  - group: Databricks-QA
  jobs:
  - job: DeployQA
    steps:
    - checkout: self

    - task: UsePythonVersion@0
      inputs:
        versionSpec: '3.x'

    - script: |
        curl -fsSL https://raw.githubusercontent.com/databricks/setup-cli/main/install.sh | bash
        databricks --version
      displayName: 'Install Databricks CLI v2'

    - script: |
        echo "Deploying notebooks to QA..."
        databricks workspace import-dir dlt-config-demo /Shared/DLT/dlt-config-demo --overwrite
        databricks workspace import-dir dlt-scd-demo /Shared/DLT/dlt-scd-demo --overwrite
      displayName: 'Deploy Notebooks to QA Workspace'
      env:
        DATABRICKS_HOST: $(DATABRICKS_HOST)
        DATABRICKS_TOKEN: $(DATABRICKS_TOKEN)

    - script: |
        echo "Deploying DLT pipeline to QA..."

        sudo apt-get update && sudo apt-get install -y jq

        PIPELINE_ID=$(databricks pipelines list-pipelines --output json | jq -r '.[] | select(.name=="DLT-Pipeline-Configuration-Driven") | .pipeline_id')

        if [ -z "$PIPELINE_ID" ]; then
          echo "Pipeline not found. Creating it..."

          jq 'del(.data_sampling) | .catalog = "qacatalog" | .configuration.catalog_name = "qacatalog"' \
            dlt-config-demo/dlt-pipeline.json > dlt-config-demo/dlt-pipeline-temp.json

          databricks pipelines create --json @dlt-config-demo/dlt-pipeline-temp.json
        else
          echo "Pipeline exists. Updating it..."

          # Get current pipeline definition from Databricks (includes the ID)
          databricks pipelines get "$PIPELINE_ID" --output json > dlt-config-demo/dlt-pipeline-existing.json

          # Modify only the catalog-related fields
          jq 'del(
              .creator_user_name,
              .last_modified,
              .last_modified_by,
              .run_as_user_name,
              .latest_updates,
              .spec,
              .state,
              .id
            )
            | .catalog = "qacatalog"
            | .configuration.catalog_name = "qacatalog"' \
          dlt-config-demo/dlt-pipeline-existing.json > dlt-config-demo/dlt-pipeline-updated.json



          databricks pipelines update --pipeline-id "$PIPELINE_ID" --json @dlt-config-demo/dlt-pipeline-updated.json
        fi
      displayName: 'Deploy DLT Pipeline (Configuration-Driven)'
      env:
        DATABRICKS_HOST: $(DATABRICKS_HOST)
        DATABRICKS_TOKEN: $(DATABRICKS_TOKEN)
