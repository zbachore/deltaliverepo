trigger:
- none

pool:
  vmImage: 'ubuntu-latest'

stages:
- stage: DeployToDev
  displayName: 'Deploy Notebooks to Dev'
  variables:
  - group: Databricks-Dev
  jobs:
  - job: DeployDev
    steps:
    - checkout: self

    - task: UsePythonVersion@0
      inputs:
        versionSpec: '3.x'

    - script: |
        curl -fsSL https://raw.githubusercontent.com/databricks/setup-cli/main/install.sh | bash
        databricks --version
      displayName: 'Install Databricks CLI v2'

    - script: |
        echo "Deploying notebooks to Dev..."
        databricks workspace import-dir dlt-config-demo /Shared/DLT/dlt-config-demo --overwrite
        databricks workspace import-dir dlt-scd-demo /Shared/DLT/dlt-scd-demo --overwrite
      displayName: 'Deploy Notebooks to Dev Workspace'
      env:
        DATABRICKS_HOST: $(DATABRICKS_HOST)
        DATABRICKS_TOKEN: $(DATABRICKS_TOKEN)

- stage: DeployToQA
  displayName: 'Deploy Notebooks to QA'
  dependsOn: DeployToDev
  variables:
  - group: Databricks-QA
  jobs:
  - job: DeployQA
    steps:
    - checkout: self

    - task: UsePythonVersion@0
      inputs:
        versionSpec: '3.x'

    - script: |
        curl -fsSL https://raw.githubusercontent.com/databricks/setup-cli/main/install.sh | bash
        databricks --version
      displayName: 'Install Databricks CLI v2'

    - script: |
        echo "Deploying notebooks to QA..."
        databricks workspace import-dir dlt-config-demo /Shared/DLT/dlt-config-demo --overwrite
        databricks workspace import-dir dlt-scd-demo /Shared/DLT/dlt-scd-demo --overwrite
      displayName: 'Deploy Notebooks to QA Workspace'
      env:
        DATABRICKS_HOST: $(DATABRICKS_HOST)
        DATABRICKS_TOKEN: $(DATABRICKS_TOKEN)

    - script: |
        echo "Deploying DLT pipeline to QA..."
        
        sudo apt-get update && sudo apt-get install -y jq

        PIPELINE_NAME="DLT-Pipeline-Configuration-Driven"

        PIPELINE_ID=$(databricks pipelines list --output json | jq -r --arg name "$PIPELINE_NAME" '.[] | select(.name==$name) | .pipeline_id')

        if [ -z "$PIPELINE_ID" ]; then
          echo "Pipeline not found. Creating new..."
          databricks pipelines create --json @dlt-config-demo/dlt-pipeline.json
        else
          echo "Pipeline exists. Updating..."

          # Download existing pipeline definition
          databricks pipelines get "$PIPELINE_ID" --output json > dlt-config-demo/dlt-pipeline-existing.json

          # Sanitize + update catalog fields
          jq --arg id "$PIPELINE_ID" --arg catalog "$(CATALOG_NAME)" '
            del(
              .creator_user_name,
              .last_modified,
              .last_modified_by,
              .run_as_user_name,
              .latest_updates,
              .spec,
              .state
            )
            | .id = $id
            | .catalog = $catalog
            | .configuration.catalog_name = $catalog
          ' dlt-config-demo/dlt-pipeline-existing.json > dlt-config-demo/dlt-pipeline-updated.json

          # Perform update
          databricks pipelines update --json @dlt-config-demo/dlt-pipeline-updated.json
        fi
      displayName: 'Deploy DLT Pipeline (Configuration-Driven)'
      env:
        DATABRICKS_HOST: $(DATABRICKS_HOST)
        DATABRICKS_TOKEN: $(DATABRICKS_TOKEN)
        CATALOG_NAME: $(CATALOG_NAME)
